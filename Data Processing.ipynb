{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021b8161-2c86-4d2f-98c0-100c62a6091b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SeanDuffy/opt/anaconda3/lib/python3.8/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import requests\n",
    "import io\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "import pyarrow\n",
    "from data_processing import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0a6b02-afea-4a9c-a110-b96944a31b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/07 13:50:37 WARN Utils: Your hostname, Seans-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.216 instead (on interface en0)\n",
      "24/04/07 13:50:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/07 13:50:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.216:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>goodreads recsys</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fefda898df0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark = SparkSession.builder.appName('goodreads recsys').getOrCreate()\n",
    "SparkSession.builder.appName('goodreads recsys').config(\"spark.driver.memory\", \"6g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14d56ba2-96c6-4913-9e3f-7c261337d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_copy=True\n",
    "local_dir='data/'\n",
    "file_names=None\n",
    "\n",
    "\"\"\"\n",
    ":param local_copy: bool: If False, data will be downloaded from online repository\n",
    ":param local_dir: str: Directory containing local files, used if local_copy == True\n",
    ":param file_names: dict: Filenames for books, authors, genres, interactions, and reviews if different from repo\n",
    ":return: pyspark.pandas Dataframe containing books info\n",
    "\"\"\"\n",
    "\n",
    "books_url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_books.json.gz'\n",
    "authors_url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_book_authors.json.gz'\n",
    "genres_url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_book_genres_initial.json.gz'\n",
    "interactions_url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_interactions.csv'\n",
    "reviews_url = 'https://datarepo.eng.ucsd.edu/mcauley_group/gdrive/goodreads/goodreads_reviews_spoiler_raw.json.gz'\n",
    "\n",
    "def extract_file_name(url):\n",
    "    return url.split('/')[-1]\n",
    "\n",
    "default_file_names = {'books': extract_file_name(books_url),\n",
    "                      'authors': extract_file_name(authors_url),\n",
    "                      'genres': extract_file_name(genres_url),\n",
    "                      'interactions': extract_file_name(interactions_url),\n",
    "                      'reviews': extract_file_name(reviews_url)}\n",
    "\n",
    "if file_names:\n",
    "    for key in [x for x in default_file_names.keys()]:\n",
    "        if key not in file_names:\n",
    "            file_names[key] = default_file_names[key]\n",
    "else:\n",
    "    file_names = default_file_names\n",
    "\n",
    "if local_copy:\n",
    "    books_path = local_dir + file_names['books']\n",
    "    authors_path = local_dir + file_names['authors']\n",
    "    genres_path = local_dir + file_names['genres']\n",
    "    interactions_path = local_dir + file_names['interactions']\n",
    "    reviews_path = local_dir + file_names['reviews']\n",
    "else:\n",
    "    books_path = io.BytesIO(requests.get(books_url).content)\n",
    "    authors_path = io.BytesIO(requests.get(authors_url).content)\n",
    "    genres_path = io.BytesIO(requests.get(genres_url).content)\n",
    "    interactions_path = io.BytesIO(requests.get(interactions_url).content)\n",
    "    reviews_path = io.BytesIO(requests.get(reviews_url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b962f42-14f4-44d1-ae2a-d43a138b5fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#books_df = spark.read.json(gzip.open(books_path))\n",
    "books_df = ps.read_json(gzip.open(books_path), lines=True, index_col='book_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b2302f-0c9f-47b9-a933-1c4403778acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = ps.read_json(gzip.open(authors_path), lines=True, index_col='author_id')\n",
    "genres_df = ps.read_json(gzip.open(genres_path), lines=True, index_col='book_id')\n",
    "reviews_df = ps.read_json(gzip.open(reviews_path), lines=True, index_col='book_id')\n",
    "int_df = ps.read_csv(interactions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4af97f-f759-4a37-96f1-c3517ac37a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = books_df.drop(\n",
    "    columns=['series', 'asin', 'kindle_asin', 'similar_books', 'link', 'url', 'image_url',\n",
    "             'edition_information', 'title_without_series', 'popular_shelves', 'publisher'])\n",
    "\n",
    "def extract_authors(authors_dict):\n",
    "    return [author['author_id'] for author in authors_dict]\n",
    "\n",
    "authors_column = books_df['authors'].apply(extract_authors)\n",
    "books_df['author_id'] = authors_column\n",
    "books_df = books_df.explode('author_id').set_index('book_id')\n",
    "books_df['author_id'] = books_df['author_id'].fillna(0).astype('int64')\n",
    "books_df = books_df.join(authors_df, how='inner', on='author_id', lsuffix='_book', rsuffix='_author')\n",
    "\n",
    "genres_df = genres_df['genres'].apply(ps.Series).join(genres_df)\n",
    "genres_df = genres_df.drop(columns=['genres']).fillna(0)\n",
    "genres_df = genres_df.set_index('book_id')\n",
    "books_df = books_df.join(genres_df, how='inner', on='book_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
